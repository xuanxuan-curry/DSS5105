{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef737205-3654-4217-856a-73e350c57985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"openai>=1.30.0\" faiss-cpu PyMuPDF python-dotenv numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb7aa5-6015-4cd2-8f0e-b256d718dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, faiss, fitz, pickle, textwrap\n",
    "from openai import OpenAI\n",
    "\n",
    "# ====== 1) OpenAI API Key ======\n",
    "# 方式A：直接在此填写（作业提交前记得删掉密钥）\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\", \"YOUR_OPENAI_API_KEY\")\n",
    "\n",
    "# 方式B：如果你有 .env 文件，取消下面两行注释\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# ====== 2) 模型名称（可按老师要求替换）======\n",
    "MODEL_EMBED = \"text-embedding-3-small\"  # 或 \"text-embedding-3-large\" / \"text-embedding-ada-002\"\n",
    "MODEL_CHAT  = \"gpt-4o-mini\"             # 或 \"gpt-3.5-turbo\"\n",
    "\n",
    "# ====== 3) 文件路径 ======\n",
    "# 方案A：你当前会话上传的路径（在本环境中可用）\n",
    "pdf_path = \"/mnt/data/Track_B_Tenancy_Agreement.pdf\"  # 如果你本地运行请改成本地路径\n",
    "\n",
    "# 方案B：本地相对路径（把文件放到 notebook 同目录，并改名）\n",
    "# pdf_path = \"tenancy_agreement.pdf\"\n",
    "\n",
    "assert os.path.exists(pdf_path), f\"找不到PDF：{pdf_path}\"\n",
    "\n",
    "# ====== 4) 索引持久化路径 ======\n",
    "INDEX_PATH  = \"tenancy_index.faiss\"\n",
    "CHUNKS_PATH = \"tenancy_chunks.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda446b5-0f64-4f92-ad12-f56f9ea257a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 读取 PDF --------\n",
    "doc = fitz.open(pdf_path)\n",
    "pages_text = []\n",
    "for p in doc:\n",
    "    pages_text.append(p.get_text())\n",
    "doc.close()\n",
    "full_text = \"\\n\".join(pages_text)\n",
    "\n",
    "# -------- 分块（尽量按段落拼到 ~1000 字符）--------\n",
    "def chunk_text(text, max_len=1000):\n",
    "    paras = [t.strip() for t in text.split(\"\\n\") if t.strip()]\n",
    "    chunks, cur = [], \"\"\n",
    "    for para in paras:\n",
    "        if cur and len(cur) + 1 + len(para) > max_len:\n",
    "            chunks.append(cur)\n",
    "            cur = para\n",
    "        else:\n",
    "            cur = para if not cur else (cur + \" \" + para)\n",
    "    if cur:\n",
    "        chunks.append(cur)\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(full_text, max_len=1000)\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "\n",
    "# -------- 批量嵌入 --------\n",
    "def embed_texts(texts, model=MODEL_EMBED, batch_size=32):\n",
    "    vecs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        resp = client.embeddings.create(model=model, input=batch)\n",
    "        vecs.extend([d.embedding for d in resp.data])\n",
    "    return np.array(vecs, dtype=np.float32)\n",
    "\n",
    "emb = embed_texts(chunks, model=MODEL_EMBED, batch_size=16)\n",
    "print(\"Embedding shape:\", emb.shape)\n",
    "\n",
    "# -------- 归一化 + 构建 FAISS 余弦相似索引 --------\n",
    "# 归一化后用内积即等价于余弦相似\n",
    "faiss.normalize_L2(emb)\n",
    "index = faiss.IndexFlatIP(emb.shape[1])\n",
    "index.add(emb)\n",
    "print(\"FAISS ntotal:\", index.ntotal)\n",
    "\n",
    "# -------- 保存索引与分块 --------\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "with open(CHUNKS_PATH, \"wb\") as f:\n",
    "    pickle.dump(chunks, f)\n",
    "print(\"Saved:\", INDEX_PATH, CHUNKS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ffce3-759a-40d5-a7cb-ccd7281a9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入索引与分块\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "with open(CHUNKS_PATH, \"rb\") as f:\n",
    "    DOC_CHUNKS = pickle.load(f)\n",
    "\n",
    "def retrieve(query, top_k=5):\n",
    "    # 查询向量\n",
    "    q_emb = np.array(\n",
    "        client.embeddings.create(model=MODEL_EMBED, input=[query]).data[0].embedding,\n",
    "        dtype=np.float32\n",
    "    )[None, :]\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    # 检索\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "    ctxs = [DOC_CHUNKS[i] for i in I[0]]\n",
    "    return ctxs, D[0]\n",
    "\n",
    "def answer_query(query, top_k=5, temperature=0.2):\n",
    "    ctxs, scores = retrieve(query, top_k=top_k)\n",
    "    context = \"\\n\\n---\\n\\n\".join(ctxs)\n",
    "\n",
    "    system_msg = (\n",
    "        \"You are a contract-aware assistant for a tenancy agreement. \"\n",
    "        \"Answer ONLY using the provided excerpts. If unsure or missing, say you don't know.\"\n",
    "    )\n",
    "    user_msg = f\"Contract excerpts:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_CHAT,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\",   \"content\": user_msg},\n",
    "        ],\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip(), ctxs, scores\n",
    "\n",
    "# 小测试\n",
    "ans, ctxs, scores = answer_query(\"What's the diplomatic clause?\", top_k=6)\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1e1d2-bfcf-4309-b64f-2d3d1c2b0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What's the diplomatic clause?\",\n",
    "    \"When things are spoiled/broken, who pays to repair?\",\n",
    "    \"What to do before returning the unit?\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(questions, 1):\n",
    "    ans, ctxs, scores = answer_query(q, top_k=6)\n",
    "    print(f\"Q{i}: {q}\\nA: {ans}\\n\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58291b-7e28-4bc9-8a94-3306e4643e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
